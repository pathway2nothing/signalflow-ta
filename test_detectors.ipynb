{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal Detectors — December 2025\n",
    "\n",
    "Testing `signalflow-ta` signal detectors on real Binance 1m OHLCV data (December 2025).  \n",
    "Analysis metrics via `signalflow.analytic.signals`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f6ee07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import asyncio\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "\n",
    "from signalflow.data.raw_store import DuckDbRawStore\n",
    "from signalflow.data.source import BinanceSpotLoader\n",
    "from signalflow.core import RawData, RawDataView, Signals\n",
    "from signalflow.analytic.signals import (\n",
    "    SignalProfileMetric,\n",
    "    SignalDistributionMetric,\n",
    "    SignalPairPrice,\n",
    ")\n",
    "from signalflow.ta.signals import (\n",
    "    BollingerBandDetector1,\n",
    "    RsiAnomalyDetector1,\n",
    "    AdxRegimeDetector1,\n",
    "    StochasticDetector1,\n",
    "    MfiDetector1,\n",
    "    DivergenceDetector1,\n",
    "    DivergenceDetector2,\n",
    "    AroonCrossDetector1,\n",
    "    CciAnomalyDetector1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e78227e",
   "metadata": {},
   "source": [
    "## 1. Download Data from Binance\n",
    "\n",
    "Download 1m spot OHLCV candles from Binance REST API into a local DuckDB store.  \n",
    "`BinanceSpotLoader.download()` handles pagination, rate limits, gap detection, and deduplication automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307239bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_PATH = Path(\"market.duckdb\")\n",
    "PAIRS = [\"BTCUSDT\", \"ETHUSDT\", \"SOLUSDT\", \"BNBUSDT\", \"XRPUSDT\"]\n",
    "DEC_START = datetime(2025, 11, 1)\n",
    "DEC_END = datetime(2026, 2, 12)\n",
    "\n",
    "# Buffer: Nov 1 (warmup) .. Jan 5 (look-ahead)\n",
    "START = datetime(2025, 11, 1)\n",
    "END = datetime(2026, 2, 12)\n",
    "\n",
    "# --- Download from Binance into DuckDB ---\n",
    "store = DuckDbRawStore(db_path=DB_PATH, data_type=\"spot\", timeframe=\"1m\")\n",
    "loader = BinanceSpotLoader(store=store, timeframe=\"1m\")\n",
    "\n",
    "await loader.download(pairs=PAIRS, start=START, end=END, fill_gaps=True)\n",
    "# Note: loader.download() closes the store connection internally\n",
    "\n",
    "print(f\"Download complete. Store: {DB_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kti4r7vz6d",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l55qbrh1jco",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load 1m data from store ---\n",
    "store = DuckDbRawStore(db_path=DB_PATH, data_type=\"spot\", timeframe=\"1m\")\n",
    "raw_data = store.to_raw_data(pairs=PAIRS, start=START, end=END)\n",
    "store.close()\n",
    "\n",
    "view = RawDataView(raw=raw_data)\n",
    "spot = raw_data[\"spot\"]\n",
    "\n",
    "print(f\"1m bars: {spot.height:,} ({spot.height // len(PAIRS):,} per pair)\")\n",
    "print(f\"Range : {spot['timestamp'].min()} -> {spot['timestamp'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f994bc14",
   "metadata": {},
   "source": [
    "## 3. Configure Detectors\n",
    "\n",
    "Parameters scaled for 1m data (periods x60 vs 1h, thresholds raised to filter noise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cf5fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Detector registry (edit this dict to choose which detectors to analyze) ---\n",
    "detectors = {\n",
    "    # \"BollingerBand\": BollingerBandDetector1(period=1200, std_dev=2.5, direction=\"both\"),\n",
    "    # \"RSI Anomaly\": RsiAnomalyDetector1(\n",
    "    #     rsi_period=840, zscore_window=6000, threshold=2.5, direction=\"both\"\n",
    "    # ),\n",
    "    # \"ADX Regime\": AdxRegimeDetector1(\n",
    "    #     adx_period=840, adx_threshold=30, direction=\"both\"\n",
    "    # ),\n",
    "    # \"Stochastic\": StochasticDetector1(\n",
    "    #     stoch_period=840, stoch_smooth_k=180, stoch_smooth_d=180, direction=\"both\"\n",
    "    # ),\n",
    "    # \"MFI\": MfiDetector1(mfi_period=840, direction=\"both\"),\n",
    "    \"Divergence\": DivergenceDetector2(\n",
    "        rsi_period=14, lookback=50, offset=60, direction=\"both\",\n",
    "    ),\n",
    "    # \"Aroon Cross\": AroonCrossDetector1(period=1500, direction=\"both\"),\n",
    "    # \"CCI Anomaly\": CciAnomalyDetector1(\n",
    "    #     cci_period=1200, zscore_window=6000, threshold=2.0, direction=\"both\"\n",
    "    # ),\n",
    "}\n",
    "\n",
    "print(f\"Configured {len(detectors)} detectors: {', '.join(detectors.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfviw5tg1b",
   "metadata": {},
   "source": [
    "## 4. Run Detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k8tk9wmmax",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deduplicate_series(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"Remove consecutive signals of the same type per pair, keep only the first.\"\"\"\n",
    "    return (\n",
    "        df.sort(\"pair\", \"timestamp\")\n",
    "        .with_columns(\n",
    "            pl.col(\"signal_type\").shift(1).over(\"pair\").alias(\"_prev_type\")\n",
    "        )\n",
    "        .filter(\n",
    "            pl.col(\"_prev_type\").is_null() | (pl.col(\"signal_type\") != pl.col(\"_prev_type\"))\n",
    "        )\n",
    "        .drop(\"_prev_type\")\n",
    "    )\n",
    "\n",
    "\n",
    "def filter_signals(signals: Signals, signal_type: str) -> Signals:\n",
    "    \"\"\"Filter signals to a specific signal_type, deduplicate series, map to signal column.\"\"\"\n",
    "    df = signals.value\n",
    "    df = df.filter(\n",
    "        (pl.col(\"timestamp\") >= DEC_START) & (pl.col(\"timestamp\") <= DEC_END)\n",
    "    )\n",
    "    df = deduplicate_series(df)\n",
    "    df = df.filter(pl.col(\"signal_type\") == signal_type)\n",
    "    df = df.with_columns(\n",
    "        pl.when(pl.col(\"signal_type\") == \"rise\").then(1)\n",
    "        .when(pl.col(\"signal_type\") == \"fall\").then(-1)\n",
    "        .otherwise(0)\n",
    "        .alias(\"signal\")\n",
    "    )\n",
    "    return Signals(df)\n",
    "\n",
    "\n",
    "# Run all detectors, store raw results\n",
    "raw_results = {}\n",
    "for name, detector in detectors.items():\n",
    "    try:\n",
    "        raw_signals = detector.run(view)\n",
    "        raw_results[name] = raw_signals\n",
    "        df = raw_signals.value\n",
    "        df_dedup = deduplicate_series(df)\n",
    "        n_rise_raw = df.filter(pl.col(\"signal_type\") == \"rise\").height\n",
    "        n_fall_raw = df.filter(pl.col(\"signal_type\") == \"fall\").height\n",
    "        n_rise = df_dedup.filter(pl.col(\"signal_type\") == \"rise\").height\n",
    "        n_fall = df_dedup.filter(pl.col(\"signal_type\") == \"fall\").height\n",
    "        print(\n",
    "            f\"  {name:20s} | rise: {n_rise_raw:6d} -> {n_rise:5d} | \"\n",
    "            f\"fall: {n_fall_raw:6d} -> {n_fall:5d}\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"  {name:20s} | ERROR: {e}\")\n",
    "\n",
    "print(f\"\\n{len(raw_results)}/{len(detectors)} detectors completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2da121",
   "metadata": {},
   "source": [
    "## 5. Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c3c6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for name, signals in raw_results.items():\n",
    "    df = signals.value.filter(\n",
    "        (pl.col(\"timestamp\") >= DEC_START) & (pl.col(\"timestamp\") <= DEC_END)\n",
    "    )\n",
    "    for pair in PAIRS:\n",
    "        pair_df = df.filter(pl.col(\"pair\") == pair)\n",
    "        rows.append({\n",
    "            \"Detector\": name,\n",
    "            \"Pair\": pair,\n",
    "            \"Rise\": pair_df.filter(pl.col(\"signal_type\") == \"rise\").height,\n",
    "            \"Fall\": pair_df.filter(pl.col(\"signal_type\") == \"fall\").height,\n",
    "            \"Total\": pair_df.height,\n",
    "        })\n",
    "\n",
    "summary = pd.DataFrame(rows)\n",
    "pivot = summary.pivot_table(\n",
    "    index=\"Detector\", columns=\"Pair\", values=\"Total\",\n",
    "    aggfunc=\"sum\", fill_value=0, margins=True, margins_name=\"TOTAL\",\n",
    ")\n",
    "pivot.sort_values(\"TOTAL\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13577c2d",
   "metadata": {},
   "source": [
    "## 6. Signal Profile — Rise vs Fall\n",
    "\n",
    "Post-signal price behavior over 48 bars (48 min on 1m data).  \n",
    "Separate plots for **rise** (bullish) and **fall** (bearish) signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4810dbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_metric = SignalProfileMetric(look_ahead=48)\n",
    "\n",
    "for signal_type in (\"rise\", \"fall\"):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  Signal type: {signal_type.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    for name, raw_signals in raw_results.items():\n",
    "        signals = filter_signals(raw_signals, signal_type)\n",
    "        if signals.value.height == 0:\n",
    "            print(f\"  {name}: no {signal_type} signals\")\n",
    "            continue\n",
    "\n",
    "        metrics, ctx = profile_metric.compute(raw_data, signals)\n",
    "        if metrics is None:\n",
    "            print(f\"  {name}: insufficient data for profile\")\n",
    "            continue\n",
    "\n",
    "        q = metrics[\"quant\"]\n",
    "        print(\n",
    "            f\"  {name:20s} | Signals: {q['n_signals']:5d} | \"\n",
    "            f\"Final mean: {q['final_mean']:+.2f}% | \"\n",
    "            f\"Avg max uplift: {q['avg_max_uplift']:.2f}%\"\n",
    "        )\n",
    "\n",
    "        fig = profile_metric.plot(metrics, ctx, raw_data, signals)\n",
    "        fig.update_layout(title_text=f\"{name} — {signal_type.upper()} — Post-Signal Profile\")\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96oec6et2vl",
   "metadata": {},
   "source": [
    "## 7. Signal-Price Overlay — Rise vs Fall (BTCUSDT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fupxc63chse",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_metric = SignalPairPrice(pairs=[\"BTCUSDT\"])\n",
    "\n",
    "for signal_type in (\"rise\", \"fall\"):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  Signal type: {signal_type.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    for name, raw_signals in raw_results.items():\n",
    "        signals = filter_signals(raw_signals, signal_type)\n",
    "        if signals.value.height == 0:\n",
    "            continue\n",
    "\n",
    "        metrics, ctx = pair_metric.compute(raw_data, signals)\n",
    "        figs = pair_metric.plot(metrics, ctx, raw_data, signals)\n",
    "        for fig in figs:\n",
    "            fig.update_layout(title_text=f\"{name} — {signal_type.upper()} — BTCUSDT\")\n",
    "            fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d183f0",
   "metadata": {},
   "source": [
    "## 8. Signal Distribution — Rise vs Fall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7158896",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_metric = SignalDistributionMetric(\n",
    "    rolling_window_minutes=24,\n",
    "    ma_window_hours=72,\n",
    ")\n",
    "\n",
    "for signal_type in (\"rise\", \"fall\"):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  Signal type: {signal_type.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    for name, raw_signals in raw_results.items():\n",
    "        signals = filter_signals(raw_signals, signal_type)\n",
    "        if signals.value.height == 0:\n",
    "            continue\n",
    "\n",
    "        metrics, ctx = dist_metric.compute(raw_data, signals)\n",
    "        if metrics is None:\n",
    "            print(f\"  {name}: no signals for distribution\")\n",
    "            continue\n",
    "\n",
    "        q = metrics[\"quant\"]\n",
    "        print(\n",
    "            f\"  {name:20s} | Pairs: {q['total_pairs']} | \"\n",
    "            f\"Mean: {q['mean_signals_per_pair']:.1f} | \"\n",
    "            f\"Max rolling: {q['max_rolling_signals']}\"\n",
    "        )\n",
    "\n",
    "        fig = dist_metric.plot(metrics, ctx, raw_data, signals)\n",
    "        fig.update_layout(title_text=f\"{name} — {signal_type.upper()} — Signal Distribution\")\n",
    "        fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sf-ta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
